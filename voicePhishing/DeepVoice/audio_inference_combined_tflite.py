import numpy as np
import tensorflow as tf
import os
from utils.load_files import load_audio_file_paths
from utils.feature_extraction import get_spectrogram, get_combined_features, get_advanced_features
from utils.predict import predict_call_with_segments, predict_with_tflite, decode_audio_librosa

# âœ… í™˜ê²½ ì„¤ì •
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "7"
print("ğŸ–¥ï¸ Physical GPUs:", tf.config.list_physical_devices('GPU'))

# âœ… ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
model_path = "quant_model/VGG19_BiLSTM_ensemble_nocudnn_lstm_best_model_2025-03-26_07-07-53.tflite"

with open(model_path, 'rb') as f:
    model_content = f.read()
print(model_content)
interpreter = tf.lite.Interpreter(model_content=model_content)
interpreter.allocate_tensors()

# âœ… ëª¨ë¸ ì…ë ¥/ì¶œë ¥ í…ì„œ ì •ë³´
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()


# âœ… í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ ì˜ˆì¸¡
test_audio_files = load_audio_file_paths("dataset/audio/tmp")

for file_path in test_audio_files:
    waveform = decode_audio_librosa(file_path)
    feature = get_advanced_features(waveform)
    feature = tf.expand_dims(feature, 0)  # (1, H, W, 1)

    prediction = predict_with_tflite(interpreter, feature)

    print(f"ğŸ“ [{os.path.basename(file_path)}]")
    print(f"ğŸ” Prediction: {prediction}")
    print(f"â¡ï¸ Deep Voice Probability: {prediction[0][1]:.4f}")
    print()

interpreter.close()