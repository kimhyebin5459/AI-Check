import numpy as np
import tensorflow as tf
import os
from utils.load import load_audio_file_paths

# âœ… í™˜ê²½ ì„¤ì •
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "7"
print("ğŸ–¥ï¸ Physical GPUs:", tf.config.list_physical_devices('GPU'))

# âœ… ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
model_path = "model/VGG19_BiLSTM_best_model_2025-03-24_08-36-46.keras"
model = tf.keras.models.load_model(model_path, compile=False)

# âœ… ì˜¤ë””ì˜¤ ë””ì½”ë”© (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ)
def decode_audio(file_path):
    audio_binary = tf.io.read_file(file_path)
    audio, sr = tf.audio.decode_wav(audio_binary, desired_channels=1)
    return tf.cast(tf.squeeze(audio, axis=-1), tf.float32)

# âœ… Mel Spectrogram ì¶”ì¶œ í•¨ìˆ˜ (í•™ìŠµ ë•Œì™€ ë™ì¼)
def get_spectrogram(waveform, sr=16000, max_frames=500):
    stft = tf.signal.stft(waveform, frame_length=512, frame_step=256)
    spectrogram = tf.abs(stft)

    num_spectrogram_bins = spectrogram.shape[-1]
    mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(
        num_mel_bins=128,
        num_spectrogram_bins=num_spectrogram_bins,
        sample_rate=sr,
        lower_edge_hertz=80.0,
        upper_edge_hertz=7600.0
    )
    mel_spectrogram = tf.matmul(spectrogram, mel_weight_matrix)
    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)

    log_mel_spectrogram = log_mel_spectrogram[:max_frames, :]
    pad_len = tf.maximum(0, max_frames - tf.shape(log_mel_spectrogram)[0])
    log_mel_spectrogram = tf.pad(log_mel_spectrogram, [[0, pad_len], [0, 0]])

    log_mel_spectrogram = tf.transpose(log_mel_spectrogram)  # (128, time)
    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)  # (128, time, 1)
    return log_mel_spectrogram

# âœ… ì˜ˆì¸¡ í•¨ìˆ˜
def predict_audio(file_path):
    try:
        waveform = decode_audio(file_path)
        feature = get_spectrogram(waveform)
        feature = tf.expand_dims(feature, 0)  # (1, 128, 500, 1)

        prediction = model.predict(feature, verbose=0)
        predicted_class = tf.argmax(prediction, axis=1).numpy()[0]
        confidence = tf.reduce_max(prediction).numpy()

        label_map = {0: "âœ… Real Voice", 1: "â€¼ï¸ Deepfake Voice"}
        print(f"ğŸ™ {file_path.split('/')[-1]} â†’ Predicted: {label_map[predicted_class]} (Confidence: {confidence:.2%})")

        return predicted_class, confidence
    except Exception as e:
        print(f"âš  Error processing {file_path}: {e}")
        return None

# âœ… í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ ì˜ˆì¸¡
test_audio_files = load_audio_file_paths("dataset/audio/tmp")

for file_path in test_audio_files:
    predict_audio(file_path)
